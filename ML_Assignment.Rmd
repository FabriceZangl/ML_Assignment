--- 
title: "Predicting the right class of exercise" 
author: "Fabrice Zangl" 
date: "September 6, 2016" 
output: 
  html_document:
    keep_md: true
---
## Introduction 
The objective of this project is to predict the class of a physical exercise. The physical exercise is to lift a weight. The class of the phyiscal exercise is the way in which the exercise is executed, which can be correct or with some form of error. The actual class of the physical exercise should be predicted by the measurements of the accelerometers. The accelerometers were located on 4 spots ( belt, forearm, arm, and dumbell) of 6 participants. 
This could for instance be used to support an automatic training coach. Such a digital coach would make suggestions on how to correct the movements to correctly execute the weight lifting exercise, for instance to avoid injuries. Of course, we would want the digital coach to correctly identify the wrong move, so that it wouldn't give wrong advice, possibly increasing the risk of injury.

## Data Gathering and Partitioning
Further details and description about the data can be found on the website describing the research experiment: http://groupware.les.inf.puc-rio.br/har. We will now first gather the data from the links provided in the assignment:
```{r get_data, echo=TRUE}
#setwd("C:/Users/zangl.f/Box Sync/private/Coursera/Data Science/Data Scientist Specialization/08 Practical Machine Learning")
url_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url_training, "assignment_training.csv")
src_training <- read.csv("assignment_training.csv")
url_validation <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url_validation, "assignment_validation.csv")
validation <- read.csv("assignment_validation.csv")
```

The 20 observations in the testing file were stored in the data frame named 'validation'. For the training and testing of the different model options, we therefore need to further partition the original training data into a training and a testing set.
```{r partition_data, echo=TRUE, fig.height=3,fig.width=3,message=FALSE} 
set.seed(1977)
if(!require(caret)) {install.packages("caret"); require(caret)}
inTrain <- createDataPartition(y = src_training$classe, p = 0.75, list = F)
training <- src_training[inTrain,]
testing <- src_training[-inTrain,]
```

## Feature selection & Pre-Processing

Before training the model, we will review the data. Using the below 3 functions in conjunction with the research description on the above website, we can conclude that the original training set is composed of 19,622 observations with 160 variables, including the variable "classe", which is the dependant variable we will want to predict in a classification exercise. 
```{r features, echo=FALSE, message=FALSE} 
str(src_training)
summary(src_training)
sum(complete.cases(src_training))
```

We will therefore need to exclude it from the training set, as well as the record ID and the name of the subject. The model could include the possibility to recognize a pattern in which a certain subject is more likely to make certain type of errors. However, given the nature of the experiment described, we will assume that this is not the case.
We can notice that many variables have many 'N/A' values. Actually, out of these observations, only 406 have a value for each variable. All these variables actually reflect summarizing values (maximum, minimum, average, amplitude, variance, skewness, kurtosis, standard deviation) of time windows. 
We will exclude these, as we won't have these features available for any given observations, notably those of the validation set.
We will also exclude any time related feature, as the duration of the exercise, the time window they belong to or the time it took place is irrelevant to the error in executing the exercise.
Lastly, we will need to apply the feature selection to all 3 datasets. For now, we will leave 'classe' as part of the datasets and remove it when needed. The other variables are simply removed from the datasets as follows:
```{r feature_selection, echo=FALSE, message=FALSE} 
sub_index <- grep("^(X|user_name|raw_timestamp_part_|cvtd_timestamp|new_window|num_window|kurtosis_|skewness_|max_|min_|amplitude_|var_|avg_|stddev_|var_)",colnames(training))
training <- training[,-sub_index]
testing <- testing[,-sub_index]
validation <- validation[,-sub_index]
```
Note that the validation dataset also as 53 variables. Although it doesn't have a classe defined, the last column includes the problem ID.

Before training the model, we will review the data. :
```{r feature_assessment, echo=TRUE, fig.height=2,fig.width=6,message=FALSE} 
M <- abs(cor(training[,-53]))
diag(M) <- 0
which(M > .8, arr.ind = T)
#pairs(training[,-53])
#featurePlot(x=training,y = training$classe, plot  ="pairs")
#my_plot <- qplot(age,wage,colour=jobclass,data=training_plot)
#my_plot + geom_smooth(method="lm", formula = y~x)
```

**comment on the result**

## Model selection & training, including pre-rocessing
We're doing a classification exercise, so blablabla:

```{r train, echo=TRUE}
set.seed(1977)
m <- train(classe ~ ., method = "rpart", preProcess = c("center","scale"), data = training)
m
m$modelType
m$method
m$finalModel
m$modelInfo
m1 <- train(classe ~ ., method = "rpart", preProcess = c("center","scale"), data = training)
m2 <- train(classe ~ ., method = "rf", preProcess = c("center","scale"), data = training)
m3 <- train(classe ~ ., method = "gbm", preProcess = c("center","scale"), data = training)

```
**comment on the result**

## Prediction

some stuff.

```{r prediction, echo=TRUE, fig.height=2,fig.width=6,message=FALSE} 
set.seed(1977)
p <- predict(m, newdata = testing)
summary(predictions)
p1 <- predict(m1, testing); p2 <- predict(m2, testing); p3 <- predict(m3, testing)
p_df <- data.frame(p1, p2, p3, classe = testing$classe)
combined_m <- train(classe ~ ., method = "rf", data = p_df)
combined_p <- predict(combined_m, p_df)

a1 <- confusionMatrix(testing$classe,p1)
a2 <- confusionMatrix(testing$classe,p2)
a3 <- confusionMatrix(testing$classe,p3)
ac <- confusionMatrix(testing$classe,combined_p)

round(a1$overall[[1]],2); round(a2$overall[[1]],2); round(a3$overall[[1]],2)
round(ac$overall[[1]],2)
```